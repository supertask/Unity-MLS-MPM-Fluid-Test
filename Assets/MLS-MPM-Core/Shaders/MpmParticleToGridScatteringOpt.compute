//
// 1. P2GScatteringOptでmass, mass_x_velocityを計算して_GridAndMassIdsBufferに保存
// 2. grid cell indexをキーに1. の配列をソート
// 3. BoundaryAndIntervalでBoundaryとIntervalを計算
// 4. GatherAndWriteでParallel reduction sumで計算してグリッドに書き出す
//
#pragma kernel P2GScatteringOpt
#pragma kernel BoundaryAndInterval
#pragma kernel GatherAndWrite

//Assets/MLS-MPM-Core/Shaders
#include "MpmStruct.hlsl"
#include "./Constant.hlsl"
#include "./Grid.hlsl"
#include "./SVD.hlsl"

#define THREAD_1D 256

float _DeltaTime;
int _NumOfParticles;


// lock-free based GPU optimazation
// x = grid index, y = lane index(particle num * neighbor grid num). Sorted by grid index
// Used in P2GScatteringOpt
// Used in P2GScatteringOpt
RWStructuredBuffer<uint2> _GridAndMassIdsBuffer;
RWStructuredBuffer<P2GMass> _P2GMassBuffer;

// if _GridBufferRead'x is 0000011111122222334444,
// _GridIndicesBufferRead will be
// Grid cell index             0 1  2  3  4
// Start index of grid buffer  0 5  11 16 18
// End index of grid buffer    4 10 15 17 21
// Then particle index is now trackable by using Start and End index
StructuredBuffer<uint2> _GridIndicesBuffer;
RWStructuredBuffer<uint2> _BoundaryAndIntervalBuffer;

//
// Particles to Grid
//
// Parameters of hyper elastic material.
float _HyperElasticHardening;
float _HyperElasticMu;
float _HyperElasticLambda;
RWStructuredBuffer<MpmParticle> _ParticlesBufferRead;
RWStructuredBuffer<MpmCell> _GridBuffer;

float _NeighborLength; //27
RWStructuredBuffer<int> _CellNeighborBuffer; //27 array

[numthreads(THREAD_1D,1,1)]
void P2GScatteringOpt(uint3 DTid : SV_DispatchThreadID)
{
    const uint particleId = DTid.x;
	MpmParticle particle = _ParticlesBufferRead[particleId];
	if (particle.type == TYPE__INACTIVE) return;

	float3x3 F = particle.Fe;
	float3x3 R = 0;
	float3x3 U ;
	float3 d;
	float3x3 V;

	float volume = particle.volume;
	float3x3 Dinv = InvApicD();
	
	GetSVD3D(F, U, d, V);
	R = mul(U, transpose(V));

	float e = 1;
	float mu = _HyperElasticMu;
	float lambda = _HyperElasticLambda;

	float j = determinant(F);
	//if(particle.type == 2)
	//{
		e = exp(_HyperElasticHardening * (1 - particle.Jp));
	//}
	// else
	// if(particle.type == 3)
	// {
	// 	mu = 0;
	// 	j = particle.Jp;
	// }

	float mup = mu * e;
	float lambdap = lambda * e;
	float3x3 P = mul((2 * mup * (F - R)), transpose(F)) + lambdap * (j - 1) * j ;

	//if(particle.type == 3)
	//{
	//	float s = particle.Jp -1;
	//	P = float3x3(s,0,0,0,s,0,0,0,s) * mu * 10;
	//}
	float3x3 stress = -(_DeltaTime * volume) * mul(Dinv , P);
	float3x3 apic = stress + particle.mass * particle.C;

	// j = clamp(j, 0.6f,20.0f);
	// float3x3 FinvT = transpose(inverse(F));
	// float3x3 P = (2.0f * mup * (F - R)) + lambdap * (j - 1.0f) * j * FinvT;
	// float3x3 stress = 1.0f / j * mul(P, transpose(F));

	int3 centerCellIndex3D = ParticlePositionToCellIndex3D(particle.position);

	//for (int gx = -1; gx <= 1; ++gx) {
	//	for (int gy = -1; gy <= 1; ++gy) {
	//		for(int gz = -1; gz <=1; ++gz) {


	//float _NumOfParticles
	//float _NeighborLength //27
	//RWStructuredBuffer<int> _CellNeighborBuffer; //27

	for (int ni = 0; ni < _NeighborLength; ni++) {
		int3 cellIndex3D = centerCellIndex3D + _CellNeighborBuffer[ni];
		uint cellIndex = CellIndex3DTo1D(cellIndex3D);

		if (InGrid(cellIndex))
		{
			float3 gridPositionWS = CellIndex3DToPositionWS(cellIndex);
			float weight = GetWeight(particle.position, _CellNeighborBuffer[ni]);

			P2GMass p2gMass;
			p2gMass.mass = weight * particle.mass;
			p2gMass.mass_x_velocity = weight * (particle.mass * particle.velocity
				+ mul(apic, (gridPositionWS - particle.position)));

			uint laneId = particleId + ni * _NumOfParticles;

			// Used for Parallel reduction sum on mass/mass_x_velocity calculation
			// _P2GMassBuffer will be sorted by grid cell index with _GridBufferWrite
			_P2GMassBuffer[laneId] = p2gMass;

			// x = grid cell index, y = lane id of _P2GMassBuffer
			// _GridAndMassIdsBuffer will be sorted by grid cell index. 
			// Used for Parallel reduction sum on mass/mass_x_velocity calculation
			_GridAndMassIdsBuffer[laneId] = uint2(cellIndex, laneId);
		}
	}

}


//
// Ming Gao, Xinlei Wang, Kui Wu, ..,
// GPU Optimization of Material Point Methods,
// ACM Transactions on Graphics (Proceedings of ACM SIGGRAPH Asia), 2018
// https://dl.acm.org/doi/10.1145/3272127.3275044
// http://pages.cs.wisc.edu/~sifakis/papers/GPU_MPM.pdf
//
[numthreads(THREAD_1D,1,1)]
void BoundaryAndInterval(uint3 DTid : SV_DispatchThreadID)
{
	const uint laneId = DTid.x;
	if (laneId-1 < 0) { return; }
	const uint cellId = _GridAndMassIdsBuffer[laneId].x;
	const uint prevCellId = _GridAndMassIdsBuffer[laneId-1].x;

	uint boundary = (laneId == 0 || cellId != prevCellId) ? 1 : 0;

	uint laneIdEnd = _GridIndicesBuffer[cellId].y;
	uint regionInterval = laneIdEnd - 1 - laneId;

	_BoundaryAndIntervalBuffer[laneId] = uint2(boundary, regionInterval);
}


groupshared float blockMass[512];
groupshared float3 blockMassXVelocity[512];

//void GatherAndWrite(
//	uint3 Gid  : SV_GroupID,
//	uint3 DTid : SV_DispatchThreadID,
//	uint3 GTid : SV_GroupThreadID,
//	uint  GI : SV_GroupIndex)
//{
[numthreads(THREAD_1D,1,1)]
void GatherAndWrite(uint3 DTid : SV_DispatchThreadID, uint GI : SV_GroupIndex)
{
	const uint laneId = DTid.x;
	uint2 cellAndMassId = _GridAndMassIdsBuffer[laneId];
	uint cellIndex  = cellAndMassId.x;
	uint massIndex  = cellAndMassId.x;
	uint2 startAndEndIndices = _GridIndicesBuffer[cellIndex];
	uint startLaneId = startAndEndIndices.x;
	uint endLaneId = startAndEndIndices.y;

	uint2 boundaryAndInterval = _BoundaryAndIntervalBuffer[laneId];
	uint boundary = boundaryAndInterval.x;
	uint regionInterval = boundaryAndInterval.y;
	uint particleId = _GridAndMassIdsBuffer[startLaneId].y;

	// Store each particle info of 256 threads
	P2GMass p2gMass = _P2GMassBuffer[massIndex];
	blockMass[GI] = p2gMass.mass;
	blockMassXVelocity[GI] = p2gMass.mass_x_velocity; //仮
	GroupMemoryBarrierWithGroupSync();
	//for (int stride = 1; stride < 512; stride *= 2) {
	for(uint stride = 1; stride < 512; stride <<= 1)
	{
		if (stride <= regionInterval) {
			// stride <= interval
			// only sum within the group(same grid index)
			blockMass[GI] += blockMass[GI+stride];
			blockMassXVelocity[GI] += blockMassXVelocity[GI+stride];
		}
		GroupMemoryBarrierWithGroupSync();
	}

	// Only the boundary node (Leader node) needs to write
	if (boundaryAndInterval.x)
	{
		MpmCell cell = _GridBuffer[cellIndex];
		cell.mass += blockMass[GI];
		cell.mass_x_velocity += blockMassXVelocity[GI];
		_GridBuffer[cellIndex] = cell; //AtomicAdd is applied
	}
}
